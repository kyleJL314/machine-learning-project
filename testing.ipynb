{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator model creation funciton\n",
    "# NOTE: this model is taken off the tensorflow website and might not be what we need at the moment \n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1) ### this is the output shape\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00188593]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## testing to make sure the model can produce random images \n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "generator = make_generator_model()\n",
    "\n",
    "noise  = tf.random.normal([1,100])\n",
    "generated_image = generator(noise,training=False)\n",
    "plt.imshow(generated_image[0,:,:,0], cmap='gray')\n",
    "\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loss functions\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)  ## helper function to get crossentropy loss\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):  ##dicriminator takes total loss of both the real image and fake image\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output) # loss for real image to an array of ones\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) # loss for the fake output as an array of zeros\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)  ##  oposite for the generator  as its loss is compated to an array of ones\n",
    "\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checkpoint system\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,discriminator_optimizer=discriminator_optimizer,generator=generator,discriminator=discriminator)\n",
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images): ## one batch of an epoch \n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])   ## calculate noise for batch\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # get gradient tapes\n",
    "        generated_images = generator(noise, training=True)  ## generate images\n",
    "        real_output = discriminator(images, training=True)   ## discriminate for both images\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)   ### calculate loss for  both\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)   ## develop gradient \n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)  \n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))  ### apply gradient with optimizer\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs): ### training per epoch\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:  ## trains one batch at a time\n",
    "            train_step(image_batch)\n",
    "        display.clear_output(wait=True)    ## after one batch, save image to look back at later \n",
    "        generate_and_save_images(generator,epoch + 1,seed)\n",
    "        if (epoch + 1) % 15 == 0:    \n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    display.clear_output(wait=True)      ### we can delete these display calls if we don't want to see whats going on in real time\n",
    "    generate_and_save_images(generator,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training loop setup:\n",
    "epochs = 50\n",
    "noise_dim=100\n",
    "BATCH_SIZE = 32\n",
    "num_examples_to_generate = 16\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_at_epoch_0050.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-11ce5d11f867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## generate images:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# displays the final image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5aca9393a7da>\u001b[0m in \u001b[0;36mdisplay_image\u001b[0;34m(epoch_no)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                  discriminator=discriminator)\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image_at_epoch_{:04d}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image_at_epoch_0050.png'"
     ]
    }
   ],
   "source": [
    "## generate images:\n",
    "display_image(epochs) # displays the final image\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e174c06fc7c59e0ec0863a51990230e5ec4e98e5b131fc56104b755f34092869"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
