{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator model creation funciton\n",
    "# NOTE: this model is taken off the tensorflow website and might not be what we need at the moment \n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1) ### this is the output shape\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.000466]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## testing to make sure the model can produce random images \n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "generator = make_generator_model()\n",
    "\n",
    "noise  = tf.random.normal([1,100])\n",
    "generated_image = generator(noise,training=False)\n",
    "plt.imshow(generated_image[0,:,:,0], cmap='gray')\n",
    "\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loss functions\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)  ## helper function to get crossentropy loss\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):  ##dicriminator takes total loss of both the real image and fake image\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output) # loss for real image to an array of ones\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) # loss for the fake output as an array of zeros\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)  ##  oposite for the generator  as its loss is compated to an array of ones\n",
    "\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checkpoint system\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,discriminator_optimizer=discriminator_optimizer,generator=generator,discriminator=discriminator)\n",
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images): ## one batch of an epoch \n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])   ## calculate noise for batch\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # get gradient tapes\n",
    "        generated_images = generator(noise, training=True)  ## generate images\n",
    "        real_output = discriminator(images, training=True)   ## discriminate for both images\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)   ### calculate loss for  both\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)   ## develop gradient \n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)  \n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))  ### apply gradient with optimizer\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs): ### training per epoch\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:  ## trains one batch at a time\n",
    "            train_step(image_batch)\n",
    "        display.clear_output(wait=True)    ## after one batch, save image to look back at later \n",
    "        generate_and_save_images(generator,epoch + 1,seed)\n",
    "        if (epoch + 1) % 15 == 0:    \n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    display.clear_output(wait=True)      ### we can delete these display calls if we don't want to see whats going on in real time\n",
    "    generate_and_save_images(generator,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training loop setup:\n",
    "epochs = 50\n",
    "noise_dim=100\n",
    "BATCH_SIZE = 32\n",
    "num_examples_to_generate = 16\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_at_epoch_0050.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2292/3467037602.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## generate images:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# displays the final image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2292/3957274100.py\u001b[0m in \u001b[0;36mdisplay_image\u001b[1;34m(epoch_no)\u001b[0m\n\u001b[0;32m      8\u001b[0m                                  discriminator=discriminator)\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image_at_epoch_{:04d}.png'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2974\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2975\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image_at_epoch_0050.png'"
     ]
    }
   ],
   "source": [
    "## generate images:\n",
    "display_image(epochs) # displays the final image\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e174c06fc7c59e0ec0863a51990230e5ec4e98e5b131fc56104b755f34092869"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
